{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b8c02cc-3560-4232-926e-6afac0daddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain-openai -q\n",
    "!pip install --upgrade langchain -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "128b37f9-3ef4-4520-b5a6-2e28911654a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE, Settings\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9a187f8-c30c-41bc-b9ff-18175a1c4f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea80fdd2-3047-4407-8c46-3c82c925d7ed",
   "metadata": {},
   "source": [
    "Method 1: manually embed the query and query the datastore for the most relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59efdb9b-8305-4f69-8c3d-79ece1aab0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(\n",
    "    path=\"chromadb\",\n",
    "    settings=Settings(),\n",
    "    tenant=DEFAULT_TENANT,\n",
    "    database=DEFAULT_DATABASE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19007777-72e4-4b15-be11-48d9237d7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chroma_client.delete_collection(name=\"documents\")  \n",
    "\n",
    "collection = chroma_client.get_collection(name=\"documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b141f7b-403a-474b-866a-26a6b66a2e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': ['0', '1'], 'embeddings': None, 'metadatas': [{'source': 'danny-moldovan-qa-using-vector-databases-lp/apidocs/api.python.langchain.com/en/latest/api_reference.html'}, {'source': 'danny-moldovan-qa-using-vector-databases-lp/apidocs/api.python.langchain.com/en/latest/api_reference.html'}], 'documents': ['langchain API Reference¶\\nlangchain.adapters¶\\nClasses¶\\nadapters.openai.ChatCompletion()\\nFunctions¶\\nadapters.openai.aenumerate(iterable[,\\xa0start])\\nAsync version of enumerate.\\nadapters.openai.convert_dict_to_message(_dict)\\nadapters.openai.convert_message_to_dict(message)\\nadapters.openai.convert_messages_for_finetuning(...)\\nConvert messages to a list of lists of dictionaries for fine-tuning.\\nadapters.openai.convert_openai_messages(messages)\\nConvert dictionaries representing OpenAI messages to LangChain format.\\nlangchain.agents¶\\nAgent is a class that uses an LLM to choose a sequence of actions to take.\\nIn Chains, a sequence of actions is hardcoded. In Agents,\\na language model is used as a reasoning engine to determine which actions\\nto take and in which order.\\nAgents select and use Tools and Toolkits for actions.\\nClass hierarchy:\\nBaseSingleActionAgent --> LLMSingleActionAgent\\n                          OpenAIFunctionsAgent\\n                          XMLAgent\\n                          Agent --> <name>Agent  # Examples: ZeroShotAgent, ChatAgent\\nBaseMultiActionAgent  --> OpenAIMultiFunctionsAgent\\nMain helpers:\\nAgentType, AgentExecutor, AgentOutputParser, AgentExecutorIterator,\\nAgentAction, AgentFinish\\nClasses¶\\nagents.agent.Agent\\nAgent that calls the language model and deciding the action.\\nagents.agent.AgentExecutor\\nAgent that is using tools.\\nagents.agent.AgentOutputParser\\nBase class for parsing agent output into agent action/finish.\\nagents.agent.BaseMultiActionAgent\\nBase Multi Action Agent class.\\nagents.agent.BaseSingleActionAgent\\nBase Single Action Agent class.\\nagents.agent.ExceptionTool\\nTool that just returns the query.\\nagents.agent.LLMSingleActionAgent\\nBase class for single action agents.\\nagents.agent.RunnableAgent\\nAgent powered by runnables.\\nagents.agent_iterator.AgentExecutorIterator(...)\\nIterator for AgentExecutor.\\nagents.agent_iterator.BaseAgentExecutorIterator()\\nBase class for AgentExecutorIterator.\\nagents.agent_toolkits.ainetwork.toolkit.AINetworkToolkit\\nToolkit for interacting with AINetwork Blockchain.\\nagents.agent_toolkits.amadeus.toolkit.AmadeusToolkit\\nToolkit for interacting with Office365.\\nagents.agent_toolkits.azure_cognitive_services.AzureCognitiveServicesToolkit\\nToolkit for Azure Cognitive Services.\\nagents.agent_toolkits.base.BaseToolkit\\nBase Toolkit representing a collection of related tools.', 'Base class for AgentExecutorIterator.\\nagents.agent_toolkits.ainetwork.toolkit.AINetworkToolkit\\nToolkit for interacting with AINetwork Blockchain.\\nagents.agent_toolkits.amadeus.toolkit.AmadeusToolkit\\nToolkit for interacting with Office365.\\nagents.agent_toolkits.azure_cognitive_services.AzureCognitiveServicesToolkit\\nToolkit for Azure Cognitive Services.\\nagents.agent_toolkits.base.BaseToolkit\\nBase Toolkit representing a collection of related tools.\\nagents.agent_toolkits.file_management.toolkit.FileManagementToolkit\\nToolkit for interacting with a Local Files.\\nagents.agent_toolkits.github.toolkit.GitHubToolkit\\nGitHub Toolkit.\\nagents.agent_toolkits.gitlab.toolkit.GitLabToolkit\\nGitLab Toolkit.\\nagents.agent_toolkits.gmail.toolkit.GmailToolkit\\nToolkit for interacting with Gmail.\\nagents.agent_toolkits.jira.toolkit.JiraToolkit\\nJira Toolkit.\\nagents.agent_toolkits.json.toolkit.JsonToolkit\\nToolkit for interacting with a JSON spec.\\nagents.agent_toolkits.multion.toolkit.MultionToolkit\\nToolkit for interacting with the Browser Agent\\nagents.agent_toolkits.nla.tool.NLATool\\nNatural Language API Tool.\\nagents.agent_toolkits.nla.toolkit.NLAToolkit\\nNatural Language API Toolkit.\\nagents.agent_toolkits.office365.toolkit.O365Toolkit\\nToolkit for interacting with Office 365.\\nagents.agent_toolkits.openapi.planner.RequestsDeleteToolWithParsing\\nA tool that sends a DELETE request and parses the response.\\nagents.agent_toolkits.openapi.planner.RequestsGetToolWithParsing\\nRequests GET tool with LLM-instructed extraction of truncated responses.\\nagents.agent_toolkits.openapi.planner.RequestsPatchToolWithParsing\\nRequests PATCH tool with LLM-instructed extraction of truncated responses.\\nagents.agent_toolkits.openapi.planner.RequestsPostToolWithParsing\\nRequests POST tool with LLM-instructed extraction of truncated responses.\\nagents.agent_toolkits.openapi.planner.RequestsPutToolWithParsing\\nRequests PUT tool with LLM-instructed extraction of truncated responses.\\nagents.agent_toolkits.openapi.spec.ReducedOpenAPISpec(...)\\nA reduced OpenAPI spec.\\nagents.agent_toolkits.openapi.toolkit.OpenAPIToolkit\\nToolkit for interacting with an OpenAPI API.\\nagents.agent_toolkits.openapi.toolkit.RequestsToolkit\\nToolkit for making REST requests.\\nagents.agent_toolkits.playwright.toolkit.PlayWrightBrowserToolkit\\nToolkit for PlayWright browser tools.']}\n"
     ]
    }
   ],
   "source": [
    "ids_to_retrieve = [\"0\", \"1\"]\n",
    "specific_data = collection.get(ids=ids_to_retrieve)#, include = [\"embeddings\"])\n",
    "print(specific_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e8a5693-ede8-43bd-97ae-96cbd5e8c0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = collection.get()  \n",
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "883d7bea-5d0e-4b15-9840-9ddfd03b7ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data['ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a181222b-9851-466b-97f6-3fae124e5a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    list_texts_replaced = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "    \n",
    "#get_embedding(\"I love Kitty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34edf58a-e06c-457c-b092-2d1313ae1c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How to improve the performance of LangChain?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66e3930d-1559-4655-aba4-d2b9252a76c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = get_embedding(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4db940ce-baef-46b5-bd9c-235470d371ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['0', '6', '8', '3', '7']],\n",
       " 'distances': [[1.1135967346221176,\n",
       "   1.2127610693400703,\n",
       "   1.243314445857681,\n",
       "   1.315484232029164,\n",
       "   1.3276152933681291]],\n",
       " 'metadatas': [[{'source': 'danny-moldovan-qa-using-vector-databases-lp/apidocs/api.python.langchain.com/en/latest/api_reference.html'},\n",
       "   {'source': 'danny-moldovan-qa-using-vector-databases-lp/apidocs/api.python.langchain.com/en/latest/api_reference.html'},\n",
       "   {'source': 'danny-moldovan-qa-using-vector-databases-lp/apidocs/api.python.langchain.com/en/latest/api_reference.html'},\n",
       "   {'source': 'danny-moldovan-qa-using-vector-databases-lp/apidocs/api.python.langchain.com/en/latest/api_reference.html'},\n",
       "   {'source': 'danny-moldovan-qa-using-vector-databases-lp/apidocs/api.python.langchain.com/en/latest/api_reference.html'}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [['langchain API Reference¶\\nlangchain.adapters¶\\nClasses¶\\nadapters.openai.ChatCompletion()\\nFunctions¶\\nadapters.openai.aenumerate(iterable[,\\xa0start])\\nAsync version of enumerate.\\nadapters.openai.convert_dict_to_message(_dict)\\nadapters.openai.convert_message_to_dict(message)\\nadapters.openai.convert_messages_for_finetuning(...)\\nConvert messages to a list of lists of dictionaries for fine-tuning.\\nadapters.openai.convert_openai_messages(messages)\\nConvert dictionaries representing OpenAI messages to LangChain format.\\nlangchain.agents¶\\nAgent is a class that uses an LLM to choose a sequence of actions to take.\\nIn Chains, a sequence of actions is hardcoded. In Agents,\\na language model is used as a reasoning engine to determine which actions\\nto take and in which order.\\nAgents select and use Tools and Toolkits for actions.\\nClass hierarchy:\\nBaseSingleActionAgent --> LLMSingleActionAgent\\n                          OpenAIFunctionsAgent\\n                          XMLAgent\\n                          Agent --> <name>Agent  # Examples: ZeroShotAgent, ChatAgent\\nBaseMultiActionAgent  --> OpenAIMultiFunctionsAgent\\nMain helpers:\\nAgentType, AgentExecutor, AgentOutputParser, AgentExecutorIterator,\\nAgentAction, AgentFinish\\nClasses¶\\nagents.agent.Agent\\nAgent that calls the language model and deciding the action.\\nagents.agent.AgentExecutor\\nAgent that is using tools.\\nagents.agent.AgentOutputParser\\nBase class for parsing agent output into agent action/finish.\\nagents.agent.BaseMultiActionAgent\\nBase Multi Action Agent class.\\nagents.agent.BaseSingleActionAgent\\nBase Single Action Agent class.\\nagents.agent.ExceptionTool\\nTool that just returns the query.\\nagents.agent.LLMSingleActionAgent\\nBase class for single action agents.\\nagents.agent.RunnableAgent\\nAgent powered by runnables.\\nagents.agent_iterator.AgentExecutorIterator(...)\\nIterator for AgentExecutor.\\nagents.agent_iterator.BaseAgentExecutorIterator()\\nBase class for AgentExecutorIterator.\\nagents.agent_toolkits.ainetwork.toolkit.AINetworkToolkit\\nToolkit for interacting with AINetwork Blockchain.\\nagents.agent_toolkits.amadeus.toolkit.AmadeusToolkit\\nToolkit for interacting with Office365.\\nagents.agent_toolkits.azure_cognitive_services.AzureCognitiveServicesToolkit\\nToolkit for Azure Cognitive Services.\\nagents.agent_toolkits.base.BaseToolkit\\nBase Toolkit representing a collection of related tools.',\n",
       "   'Unified method for loading an agent from LangChainHub or local fs.\\nagents.loading.load_agent_from_config(config)\\nLoad agent from Config Dict.\\nagents.utils.validate_tools_single_input(...)\\nValidate tools for single input.\\nlangchain.agents.format_scratchpad¶\\nLogic for formatting intermediate steps into an agent scratchpad.\\nIntermediate steps refers to the list of (AgentAction, observation) tuples\\nthat result from previous iterations of the agent.\\nDepending on the prompting strategy you are using, you may want to format these\\ndifferently before passing them into the LLM.\\nFunctions¶\\nagents.format_scratchpad.log.format_log_to_str(...)\\nConstruct the scratchpad that lets the agent continue its thought process.\\nagents.format_scratchpad.log_to_messages.format_log_to_messages(...)\\nConstruct the scratchpad that lets the agent continue its thought process.\\nagents.format_scratchpad.openai_functions.format_to_openai_functions(...)\\nFormat intermediate steps.\\nagents.format_scratchpad.xml.format_xml(...)\\nlangchain.agents.output_parsers¶\\nParsing utils to go from string to AgentAction or Agent Finish.\\nAgentAction means that an action should be taken.\\nThis contains the name of the tool to use, the input to pass to that tool,\\nand a log variable (which contains a log of the agent’s thinking).\\nAgentFinish means that a response should be given.\\nThis contains a return_values dictionary. This usually contains a\\nsingle output key, but can be extended to contain more.\\nThis also contains a log variable (which contains a log of the agent’s thinking).\\nClasses¶\\nagents.output_parsers.json.JSONAgentOutputParser\\nParses tool invocations and final answers in XML format.\\nagents.output_parsers.openai_functions.OpenAIFunctionsAgentOutputParser\\nParses a message into agent action/finish.\\nagents.output_parsers.react_json_single_input.ReActJsonSingleInputOutputParser\\nParses ReAct-style LLM calls that have a single tool input in json format.\\nagents.output_parsers.react_single_input.ReActSingleInputOutputParser\\nParses ReAct-style LLM calls that have a single tool input.\\nagents.output_parsers.self_ask.SelfAskOutputParser\\nParses self-ask style LLM calls.\\nagents.output_parsers.xml.XMLAgentOutputParser\\nParses tool invocations and final answers in XML format.\\nlangchain.cache¶\\nWarning\\nBeta Feature!',\n",
       "   'Cache that uses SQAlchemy as a backend.\\ncache.SQLiteCache([database_path])\\nCache that uses SQLite as a backend.\\nFunctions¶\\nlangchain.callbacks¶\\nCallback handlers allow listening to events in LangChain.\\nClass hierarchy:\\nBaseCallbackHandler --> <name>CallbackHandler  # Example: AimCallbackHandler\\nClasses¶\\ncallbacks.aim_callback.AimCallbackHandler([...])\\nCallback Handler that logs to Aim.\\ncallbacks.aim_callback.BaseMetadataCallbackHandler()\\nThis class handles the metadata and associated function states for callbacks.\\ncallbacks.argilla_callback.ArgillaCallbackHandler(...)\\nCallback Handler that logs into Argilla.\\ncallbacks.arize_callback.ArizeCallbackHandler([...])\\nCallback Handler that logs to Arize.\\ncallbacks.arthur_callback.ArthurCallbackHandler(...)\\nCallback Handler that logs to Arthur platform.\\ncallbacks.base.AsyncCallbackHandler()\\nAsync callback handler that can be used to handle callbacks from langchain.\\ncallbacks.base.BaseCallbackHandler()\\nBase callback handler that can be used to handle callbacks from langchain.\\ncallbacks.base.BaseCallbackManager(handlers)\\nBase callback manager that handles callbacks from LangChain.\\ncallbacks.base.CallbackManagerMixin()\\nMixin for callback manager.\\ncallbacks.base.ChainManagerMixin()\\nMixin for chain callbacks.\\ncallbacks.base.LLMManagerMixin()\\nMixin for LLM callbacks.\\ncallbacks.base.RetrieverManagerMixin()\\nMixin for Retriever callbacks.\\ncallbacks.base.RunManagerMixin()\\nMixin for run manager.\\ncallbacks.base.ToolManagerMixin()\\nMixin for tool callbacks.\\ncallbacks.clearml_callback.ClearMLCallbackHandler([...])\\nCallback Handler that logs to ClearML.\\ncallbacks.comet_ml_callback.CometCallbackHandler([...])\\nCallback Handler that logs to Comet.\\ncallbacks.confident_callback.DeepEvalCallbackHandler(metrics)\\nCallback Handler that logs into deepeval.\\ncallbacks.context_callback.ContextCallbackHandler([...])\\nCallback Handler that records transcripts to the Context service.\\ncallbacks.file.FileCallbackHandler(filename)\\nCallback Handler that writes to a file.\\ncallbacks.flyte_callback.FlyteCallbackHandler()\\nThis callback handler that is used within a Flyte task.\\ncallbacks.human.HumanApprovalCallbackHandler(...)\\nCallback for manually validating values.\\ncallbacks.human.HumanRejectedException\\nException to raise when a person manually review and rejects a value.\\ncallbacks.infino_callback.InfinoCallbackHandler([...])\\nCallback Handler that logs to Infino.\\ncallbacks.labelstudio_callback.LabelStudioCallbackHandler([...])',\n",
       "   'agents.mrkl.base.MRKLChain\\n[Deprecated] Chain that implements the MRKL system.\\nagents.mrkl.base.ZeroShotAgent\\nAgent for the MRKL chain.\\nagents.mrkl.output_parser.MRKLOutputParser\\nMRKL Output parser for the chat agent.\\nagents.openai_functions_agent.agent_token_buffer_memory.AgentTokenBufferMemory\\nMemory used to save agent output AND intermediate steps.\\nagents.openai_functions_agent.base.OpenAIFunctionsAgent\\nAn Agent driven by OpenAIs function powered API.\\nagents.openai_functions_multi_agent.base.OpenAIMultiFunctionsAgent\\nAn Agent driven by OpenAIs function powered API.\\nagents.output_parsers.json.JSONAgentOutputParser\\nParses tool invocations and final answers in XML format.\\nagents.output_parsers.openai_functions.OpenAIFunctionsAgentOutputParser\\nParses a message into agent action/finish.\\nagents.output_parsers.react_json_single_input.ReActJsonSingleInputOutputParser\\nParses ReAct-style LLM calls that have a single tool input in json format.\\nagents.output_parsers.react_single_input.ReActSingleInputOutputParser\\nParses ReAct-style LLM calls that have a single tool input.\\nagents.output_parsers.self_ask.SelfAskOutputParser\\nParses self-ask style LLM calls.\\nagents.output_parsers.xml.XMLAgentOutputParser\\nParses tool invocations and final answers in XML format.\\nagents.react.base.DocstoreExplorer(docstore)\\nClass to assist with exploration of a document store.\\nagents.react.base.ReActChain\\n[Deprecated] Chain that implements the ReAct paper.\\nagents.react.base.ReActDocstoreAgent\\nAgent for the ReAct chain.\\nagents.react.base.ReActTextWorldAgent\\nAgent for the ReAct TextWorld chain.\\nagents.react.output_parser.ReActOutputParser\\nOutput parser for the ReAct agent.\\nagents.schema.AgentScratchPadChatPromptTemplate\\nChat prompt template for the agent scratchpad.\\nagents.self_ask_with_search.base.SelfAskWithSearchAgent\\nAgent for the self-ask-with-search paper.\\nagents.self_ask_with_search.base.SelfAskWithSearchChain\\n[Deprecated] Chain that does self-ask with search.\\nagents.structured_chat.base.StructuredChatAgent\\nStructured Chat Agent.\\nagents.structured_chat.output_parser.StructuredChatOutputParser\\nOutput parser for the structured chat agent.',\n",
       "   'agents.output_parsers.react_single_input.ReActSingleInputOutputParser\\nParses ReAct-style LLM calls that have a single tool input.\\nagents.output_parsers.self_ask.SelfAskOutputParser\\nParses self-ask style LLM calls.\\nagents.output_parsers.xml.XMLAgentOutputParser\\nParses tool invocations and final answers in XML format.\\nlangchain.cache¶\\nWarning\\nBeta Feature!\\nCache provides an optional caching layer for LLMs.\\nCache is useful for two reasons:\\nIt can save you money by reducing the number of API calls you make to the LLM\\nprovider if you’re often requesting the same completion multiple times.\\nIt can speed up your application by reducing the number of API calls you make\\nto the LLM provider.\\nCache directly competes with Memory. See documentation for Pros and Cons.\\nClass hierarchy:\\nBaseCache --> <name>Cache  # Examples: InMemoryCache, RedisCache, GPTCache\\nClasses¶\\ncache.CassandraCache([session,\\xa0keyspace,\\xa0...])\\nCache that uses Cassandra / Astra DB as a backend.\\ncache.CassandraSemanticCache(session,\\xa0...[,\\xa0...])\\nCache that uses Cassandra as a vector-store backend for semantic (i.e.\\ncache.FullLLMCache(**kwargs)\\nSQLite table for full LLM Cache (all generations).\\ncache.GPTCache([init_func])\\nCache that uses GPTCache as a backend.\\ncache.InMemoryCache()\\nCache that stores things in memory.\\ncache.MomentoCache(cache_client,\\xa0cache_name,\\xa0*)\\nCache that uses Momento as a backend.\\ncache.RedisCache(redis_,\\xa0*[,\\xa0ttl])\\nCache that uses Redis as a backend.\\ncache.RedisSemanticCache(redis_url,\\xa0embedding)\\nCache that uses Redis as a vector-store backend.\\ncache.SQLAlchemyCache(engine,\\xa0cache_schema)\\nCache that uses SQAlchemy as a backend.\\ncache.SQLiteCache([database_path])\\nCache that uses SQLite as a backend.\\nFunctions¶\\nlangchain.callbacks¶\\nCallback handlers allow listening to events in LangChain.\\nClass hierarchy:\\nBaseCallbackHandler --> <name>CallbackHandler  # Example: AimCallbackHandler\\nClasses¶\\ncallbacks.aim_callback.AimCallbackHandler([...])\\nCallback Handler that logs to Aim.\\ncallbacks.aim_callback.BaseMetadataCallbackHandler()']]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the collection's `query` method for retrieval\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding],\n",
    "    n_results=5,  \n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d20b2f-9829-4532-ab5e-6765ff4252d8",
   "metadata": {},
   "source": [
    "Method 2: By creating a retriever based on the datastore and querying it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b0acf83-6e92-4e94-a148-dfce157870ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# Initialize Chroma vector store\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"documents\",  # The name of the collection in your Chroma DB\n",
    "    client=chroma_client,  # The initialized Chroma client\n",
    "    embedding_function=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce74503f-02a3-4138-a2a1-941a3a7a553f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"callbacks.manager.CallbackManager(handlers)\\nCallback manager that handles callbacks from langchain.\\ncallbacks.manager.CallbackManagerForChainGroup(...)\\nInitialize callback manager.\\ncallbacks.manager.CallbackManagerForChainRun(*,\\xa0...)\\nCallback manager for chain run.\\ncallbacks.manager.CallbackManagerForLLMRun(*,\\xa0...)\\nCallback manager for LLM run.\\ncallbacks.manager.CallbackManagerForRetrieverRun(*,\\xa0...)\\nCallback manager for retriever run.\\ncallbacks.manager.CallbackManagerForToolRun(*,\\xa0...)\\nCallback manager for tool run.\\ncallbacks.manager.ParentRunManager(*,\\xa0...[,\\xa0...])\\nSync Parent Run Manager.\\ncallbacks.manager.RunManager(*,\\xa0run_id,\\xa0...)\\nSync Run Manager.\\ncallbacks.mlflow_callback.MlflowCallbackHandler([...])\\nCallback Handler that logs metrics and artifacts to mlflow server.\\ncallbacks.mlflow_callback.MlflowLogger(**kwargs)\\nCallback Handler that logs metrics and artifacts to mlflow server.\\ncallbacks.openai_info.OpenAICallbackHandler()\\nCallback Handler that tracks OpenAI info.\\ncallbacks.promptlayer_callback.PromptLayerCallbackHandler([...])\\nCallback handler for promptlayer.\\ncallbacks.sagemaker_callback.SageMakerCallbackHandler(run)\\nCallback Handler that logs prompt artifacts and metrics to SageMaker Experiments.\\ncallbacks.stdout.StdOutCallbackHandler([color])\\nCallback Handler that prints to std out.\\ncallbacks.streaming_aiter.AsyncIteratorCallbackHandler()\\nCallback handler that returns an async iterator.\\ncallbacks.streaming_aiter_final_only.AsyncFinalIteratorCallbackHandler(*)\\nCallback handler that returns an async iterator.\\ncallbacks.streaming_stdout.StreamingStdOutCallbackHandler()\\nCallback handler for streaming.\\ncallbacks.streaming_stdout_final_only.FinalStreamingStdOutCallbackHandler(*)\\nCallback handler for streaming in agents.\\ncallbacks.streamlit.mutable_expander.ChildRecord(...)\\nThe child record as a NamedTuple.\\ncallbacks.streamlit.mutable_expander.ChildType(value)\\nThe enumerator of the child type.\\ncallbacks.streamlit.mutable_expander.MutableExpander(...)\\nA Streamlit expander that can be renamed and dynamically expanded/collapsed.\\ncallbacks.streamlit.streamlit_callback_handler.LLMThought(...)\\nA thought in the LLM's thought stream.\\ncallbacks.streamlit.streamlit_callback_handler.LLMThoughtLabeler()\\nGenerates markdown labels for LLMThought containers.\\ncallbacks.streamlit.streamlit_callback_handler.LLMThoughtState(value)\\nEnumerator of the LLMThought state.\", metadata={'source': 'danny-moldovan-qa-using-vector-databases-lp/apidocs/api.python.langchain.com/en/latest/api_reference.html'}),\n",
       " Document(page_content='callbacks.flyte_callback.FlyteCallbackHandler()\\nThis callback handler that is used within a Flyte task.\\ncallbacks.human.HumanApprovalCallbackHandler(...)\\nCallback for manually validating values.\\ncallbacks.human.HumanRejectedException\\nException to raise when a person manually review and rejects a value.\\ncallbacks.infino_callback.InfinoCallbackHandler([...])\\nCallback Handler that logs to Infino.\\ncallbacks.labelstudio_callback.LabelStudioCallbackHandler([...])\\nLabel Studio callback handler.\\ncallbacks.labelstudio_callback.LabelStudioMode(value)\\ncallbacks.llmonitor_callback.LLMonitorCallbackHandler([...])\\nInitializes the LLMonitorCallbackHandler. #### Parameters:     - app_id: The app id of the app you want to report to. Defaults to     None, which means that LLMONITOR_APP_ID will be used. - api_url: The url of the LLMonitor API. Defaults to None,     which means that either LLMONITOR_API_URL environment variable     or https://app.llmonitor.com will be used.\\ncallbacks.llmonitor_callback.UserContextManager(user_id)\\ncallbacks.manager.AsyncCallbackManager(handlers)\\nAsync callback manager that handles callbacks from LangChain.\\ncallbacks.manager.AsyncCallbackManagerForChainGroup(...)\\nInitialize callback manager.\\ncallbacks.manager.AsyncCallbackManagerForChainRun(*,\\xa0...)\\nAsync callback manager for chain run.\\ncallbacks.manager.AsyncCallbackManagerForLLMRun(*,\\xa0...)\\nAsync callback manager for LLM run.\\ncallbacks.manager.AsyncCallbackManagerForRetrieverRun(*,\\xa0...)\\nAsync callback manager for retriever run.\\ncallbacks.manager.AsyncCallbackManagerForToolRun(*,\\xa0...)\\nAsync callback manager for tool run.\\ncallbacks.manager.AsyncParentRunManager(*,\\xa0...)\\nAsync Parent Run Manager.\\ncallbacks.manager.AsyncRunManager(*,\\xa0run_id,\\xa0...)\\nAsync Run Manager.\\ncallbacks.manager.BaseRunManager(*,\\xa0run_id,\\xa0...)\\nBase class for run manager (a bound callback manager).\\ncallbacks.manager.CallbackManager(handlers)\\nCallback manager that handles callbacks from langchain.\\ncallbacks.manager.CallbackManagerForChainGroup(...)\\nInitialize callback manager.\\ncallbacks.manager.CallbackManagerForChainRun(*,\\xa0...)\\nCallback manager for chain run.\\ncallbacks.manager.CallbackManagerForLLMRun(*,\\xa0...)\\nCallback manager for LLM run.\\ncallbacks.manager.CallbackManagerForRetrieverRun(*,\\xa0...)\\nCallback manager for retriever run.', metadata={'source': 'danny-moldovan-qa-using-vector-databases-lp/apidocs/api.python.langchain.com/en/latest/api_reference.html'}),\n",
       " Document(page_content='Unified method for loading an agent from LangChainHub or local fs.\\nagents.loading.load_agent_from_config(config)\\nLoad agent from Config Dict.\\nagents.utils.validate_tools_single_input(...)\\nValidate tools for single input.\\nlangchain.agents.format_scratchpad¶\\nLogic for formatting intermediate steps into an agent scratchpad.\\nIntermediate steps refers to the list of (AgentAction, observation) tuples\\nthat result from previous iterations of the agent.\\nDepending on the prompting strategy you are using, you may want to format these\\ndifferently before passing them into the LLM.\\nFunctions¶\\nagents.format_scratchpad.log.format_log_to_str(...)\\nConstruct the scratchpad that lets the agent continue its thought process.\\nagents.format_scratchpad.log_to_messages.format_log_to_messages(...)\\nConstruct the scratchpad that lets the agent continue its thought process.\\nagents.format_scratchpad.openai_functions.format_to_openai_functions(...)\\nFormat intermediate steps.\\nagents.format_scratchpad.xml.format_xml(...)\\nlangchain.agents.output_parsers¶\\nParsing utils to go from string to AgentAction or Agent Finish.\\nAgentAction means that an action should be taken.\\nThis contains the name of the tool to use, the input to pass to that tool,\\nand a log variable (which contains a log of the agent’s thinking).\\nAgentFinish means that a response should be given.\\nThis contains a return_values dictionary. This usually contains a\\nsingle output key, but can be extended to contain more.\\nThis also contains a log variable (which contains a log of the agent’s thinking).\\nClasses¶\\nagents.output_parsers.json.JSONAgentOutputParser\\nParses tool invocations and final answers in XML format.\\nagents.output_parsers.openai_functions.OpenAIFunctionsAgentOutputParser\\nParses a message into agent action/finish.\\nagents.output_parsers.react_json_single_input.ReActJsonSingleInputOutputParser\\nParses ReAct-style LLM calls that have a single tool input in json format.\\nagents.output_parsers.react_single_input.ReActSingleInputOutputParser\\nParses ReAct-style LLM calls that have a single tool input.\\nagents.output_parsers.self_ask.SelfAskOutputParser\\nParses self-ask style LLM calls.\\nagents.output_parsers.xml.XMLAgentOutputParser\\nParses tool invocations and final answers in XML format.\\nlangchain.cache¶\\nWarning\\nBeta Feature!', metadata={'source': 'danny-moldovan-qa-using-vector-databases-lp/apidocs/api.python.langchain.com/en/latest/api_reference.html'}),\n",
       " Document(page_content='langchain API Reference¶\\nlangchain.adapters¶\\nClasses¶\\nadapters.openai.ChatCompletion()\\nFunctions¶\\nadapters.openai.aenumerate(iterable[,\\xa0start])\\nAsync version of enumerate.\\nadapters.openai.convert_dict_to_message(_dict)\\nadapters.openai.convert_message_to_dict(message)\\nadapters.openai.convert_messages_for_finetuning(...)\\nConvert messages to a list of lists of dictionaries for fine-tuning.\\nadapters.openai.convert_openai_messages(messages)\\nConvert dictionaries representing OpenAI messages to LangChain format.\\nlangchain.agents¶\\nAgent is a class that uses an LLM to choose a sequence of actions to take.\\nIn Chains, a sequence of actions is hardcoded. In Agents,\\na language model is used as a reasoning engine to determine which actions\\nto take and in which order.\\nAgents select and use Tools and Toolkits for actions.\\nClass hierarchy:\\nBaseSingleActionAgent --> LLMSingleActionAgent\\n                          OpenAIFunctionsAgent\\n                          XMLAgent\\n                          Agent --> <name>Agent  # Examples: ZeroShotAgent, ChatAgent\\nBaseMultiActionAgent  --> OpenAIMultiFunctionsAgent\\nMain helpers:\\nAgentType, AgentExecutor, AgentOutputParser, AgentExecutorIterator,\\nAgentAction, AgentFinish\\nClasses¶\\nagents.agent.Agent\\nAgent that calls the language model and deciding the action.\\nagents.agent.AgentExecutor\\nAgent that is using tools.\\nagents.agent.AgentOutputParser\\nBase class for parsing agent output into agent action/finish.\\nagents.agent.BaseMultiActionAgent\\nBase Multi Action Agent class.\\nagents.agent.BaseSingleActionAgent\\nBase Single Action Agent class.\\nagents.agent.ExceptionTool\\nTool that just returns the query.\\nagents.agent.LLMSingleActionAgent\\nBase class for single action agents.\\nagents.agent.RunnableAgent\\nAgent powered by runnables.\\nagents.agent_iterator.AgentExecutorIterator(...)\\nIterator for AgentExecutor.\\nagents.agent_iterator.BaseAgentExecutorIterator()\\nBase class for AgentExecutorIterator.\\nagents.agent_toolkits.ainetwork.toolkit.AINetworkToolkit\\nToolkit for interacting with AINetwork Blockchain.\\nagents.agent_toolkits.amadeus.toolkit.AmadeusToolkit\\nToolkit for interacting with Office365.\\nagents.agent_toolkits.azure_cognitive_services.AzureCognitiveServicesToolkit\\nToolkit for Azure Cognitive Services.\\nagents.agent_toolkits.base.BaseToolkit\\nBase Toolkit representing a collection of related tools.', metadata={'source': 'danny-moldovan-qa-using-vector-databases-lp/apidocs/api.python.langchain.com/en/latest/api_reference.html'})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.search('kitty bank', search_type='similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f37c46e-fb8b-4181-a9ea-1727a706bf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search('kitty bank', k = 3)\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cac97f8a-50e2-457c-870c-85816d61aee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"callbacks.manager.CallbackManager(handlers)\\nCallback manager that handles callbacks from langchain.\\ncallbacks.manager.CallbackManagerForChainGroup(...)\\nInitialize callback manager.\\ncallbacks.manager.CallbackManagerForChainRun(*,\\xa0...)\\nCallback manager for chain run.\\ncallbacks.manager.CallbackManagerForLLMRun(*,\\xa0...)\\nCallback manager for LLM run.\\ncallbacks.manager.CallbackManagerForRetrieverRun(*,\\xa0...)\\nCallback manager for retriever run.\\ncallbacks.manager.CallbackManagerForToolRun(*,\\xa0...)\\nCallback manager for tool run.\\ncallbacks.manager.ParentRunManager(*,\\xa0...[,\\xa0...])\\nSync Parent Run Manager.\\ncallbacks.manager.RunManager(*,\\xa0run_id,\\xa0...)\\nSync Run Manager.\\ncallbacks.mlflow_callback.MlflowCallbackHandler([...])\\nCallback Handler that logs metrics and artifacts to mlflow server.\\ncallbacks.mlflow_callback.MlflowLogger(**kwargs)\\nCallback Handler that logs metrics and artifacts to mlflow server.\\ncallbacks.openai_info.OpenAICallbackHandler()\\nCallback Handler that tracks OpenAI info.\\ncallbacks.promptlayer_callback.PromptLayerCallbackHandler([...])\\nCallback handler for promptlayer.\\ncallbacks.sagemaker_callback.SageMakerCallbackHandler(run)\\nCallback Handler that logs prompt artifacts and metrics to SageMaker Experiments.\\ncallbacks.stdout.StdOutCallbackHandler([color])\\nCallback Handler that prints to std out.\\ncallbacks.streaming_aiter.AsyncIteratorCallbackHandler()\\nCallback handler that returns an async iterator.\\ncallbacks.streaming_aiter_final_only.AsyncFinalIteratorCallbackHandler(*)\\nCallback handler that returns an async iterator.\\ncallbacks.streaming_stdout.StreamingStdOutCallbackHandler()\\nCallback handler for streaming.\\ncallbacks.streaming_stdout_final_only.FinalStreamingStdOutCallbackHandler(*)\\nCallback handler for streaming in agents.\\ncallbacks.streamlit.mutable_expander.ChildRecord(...)\\nThe child record as a NamedTuple.\\ncallbacks.streamlit.mutable_expander.ChildType(value)\\nThe enumerator of the child type.\\ncallbacks.streamlit.mutable_expander.MutableExpander(...)\\nA Streamlit expander that can be renamed and dynamically expanded/collapsed.\\ncallbacks.streamlit.streamlit_callback_handler.LLMThought(...)\\nA thought in the LLM's thought stream.\\ncallbacks.streamlit.streamlit_callback_handler.LLMThoughtLabeler()\\nGenerates markdown labels for LLMThought containers.\\ncallbacks.streamlit.streamlit_callback_handler.LLMThoughtState(value)\\nEnumerator of the LLMThought state.\", metadata={'source': 'danny-moldovan-qa-using-vector-databases-lp/apidocs/api.python.langchain.com/en/latest/api_reference.html'})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cc0217-d6b7-4555-a04b-abb6e89afe60",
   "metadata": {},
   "source": [
    "Method 3: By creating a QA chain using LangChain and adding a prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "316183b2-0aec-40cf-87ea-169f011c32aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ef7f016-f9ae-4f20-bc58-f97f921bcf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is HumanRejectedException?',\n",
       " 'result': \" HumanRejectedException is a type of exception that is thrown when a human rejects an agent's response. This can occur in a self-ask-style LLM call or in a structured chat agent.\",\n",
       " 'source_documents': [Document(page_content='Unified method for loading an agent from LangChainHub or local fs.\\nagents.loading.load_agent_from_config(config)\\nLoad agent from Config Dict.\\nagents.utils.validate_tools_single_input(...)\\nValidate tools for single input.\\nlangchain.agents.format_scratchpad¶\\nLogic for formatting intermediate steps into an agent scratchpad.\\nIntermediate steps refers to the list of (AgentAction, observation) tuples\\nthat result from previous iterations of the agent.\\nDepending on the prompting strategy you are using, you may want to format these\\ndifferently before passing them into the LLM.\\nFunctions¶\\nagents.format_scratchpad.log.format_log_to_str(...)\\nConstruct the scratchpad that lets the agent continue its thought process.\\nagents.format_scratchpad.log_to_messages.format_log_to_messages(...)\\nConstruct the scratchpad that lets the agent continue its thought process.\\nagents.format_scratchpad.openai_functions.format_to_openai_functions(...)\\nFormat intermediate steps.\\nagents.format_scratchpad.xml.format_xml(...)\\nlangchain.agents.output_parsers¶\\nParsing utils to go from string to AgentAction or Agent Finish.\\nAgentAction means that an action should be taken.\\nThis contains the name of the tool to use, the input to pass to that tool,\\nand a log variable (which contains a log of the agent’s thinking).\\nAgentFinish means that a response should be given.\\nThis contains a return_values dictionary. This usually contains a\\nsingle output key, but can be extended to contain more.\\nThis also contains a log variable (which contains a log of the agent’s thinking).\\nClasses¶\\nagents.output_parsers.json.JSONAgentOutputParser\\nParses tool invocations and final answers in XML format.\\nagents.output_parsers.openai_functions.OpenAIFunctionsAgentOutputParser\\nParses a message into agent action/finish.\\nagents.output_parsers.react_json_single_input.ReActJsonSingleInputOutputParser\\nParses ReAct-style LLM calls that have a single tool input in json format.\\nagents.output_parsers.react_single_input.ReActSingleInputOutputParser\\nParses ReAct-style LLM calls that have a single tool input.\\nagents.output_parsers.self_ask.SelfAskOutputParser\\nParses self-ask style LLM calls.\\nagents.output_parsers.xml.XMLAgentOutputParser\\nParses tool invocations and final answers in XML format.\\nlangchain.cache¶\\nWarning\\nBeta Feature!', metadata={'source': 'danny-moldovan-qa-using-vector-databases-lp/apidocs/api.python.langchain.com/en/latest/api_reference.html'}),\n",
       "  Document(page_content='Construct a Power BI agent from an LLM and tools.\\nagents.agent_toolkits.powerbi.chat_base.create_pbi_chat_agent(llm)\\nConstruct a Power BI agent from a Chat LLM and tools.\\nagents.agent_toolkits.python.base.create_python_agent(...)\\nConstruct a python agent from an LLM and tool.\\nagents.agent_toolkits.spark.base.create_spark_dataframe_agent(llm,\\xa0df)\\nConstruct a Spark agent from an LLM and dataframe.\\nagents.agent_toolkits.spark_sql.base.create_spark_sql_agent(...)\\nConstruct a Spark SQL agent from an LLM and tools.\\nagents.agent_toolkits.sql.base.create_sql_agent(...)\\nConstruct an SQL agent from an LLM and tools.\\nagents.agent_toolkits.vectorstore.base.create_vectorstore_agent(...)\\nConstruct a VectorStore agent from an LLM and tools.\\nagents.agent_toolkits.vectorstore.base.create_vectorstore_router_agent(...)\\nConstruct a VectorStore router agent from an LLM and tools.\\nagents.agent_toolkits.xorbits.base.create_xorbits_agent(...)\\nConstruct a xorbits agent from an LLM and dataframe.\\nagents.format_scratchpad.log.format_log_to_str(...)\\nConstruct the scratchpad that lets the agent continue its thought process.\\nagents.format_scratchpad.log_to_messages.format_log_to_messages(...)\\nConstruct the scratchpad that lets the agent continue its thought process.\\nagents.format_scratchpad.openai_functions.format_to_openai_functions(...)\\nFormat intermediate steps.\\nagents.format_scratchpad.xml.format_xml(...)\\nagents.initialize.initialize_agent(tools,\\xa0llm)\\nLoad an agent executor given tools and LLM.\\nagents.load_tools.get_all_tool_names()\\nGet a list of all possible tool names.\\nagents.load_tools.load_huggingface_tool(...)\\nLoads a tool from the HuggingFace Hub.\\nagents.load_tools.load_tools(tool_names[,\\xa0...])\\nLoad tools based on their name.\\nagents.loading.load_agent(path,\\xa0**kwargs)\\nUnified method for loading an agent from LangChainHub or local fs.\\nagents.loading.load_agent_from_config(config)\\nLoad agent from Config Dict.\\nagents.utils.validate_tools_single_input(...)\\nValidate tools for single input.\\nlangchain.agents.format_scratchpad¶\\nLogic for formatting intermediate steps into an agent scratchpad.\\nIntermediate steps refers to the list of (AgentAction, observation) tuples\\nthat result from previous iterations of the agent.', metadata={'source': 'danny-moldovan-qa-using-vector-databases-lp/apidocs/api.python.langchain.com/en/latest/api_reference.html'}),\n",
       "  Document(page_content='Base class for AgentExecutorIterator.\\nagents.agent_toolkits.ainetwork.toolkit.AINetworkToolkit\\nToolkit for interacting with AINetwork Blockchain.\\nagents.agent_toolkits.amadeus.toolkit.AmadeusToolkit\\nToolkit for interacting with Office365.\\nagents.agent_toolkits.azure_cognitive_services.AzureCognitiveServicesToolkit\\nToolkit for Azure Cognitive Services.\\nagents.agent_toolkits.base.BaseToolkit\\nBase Toolkit representing a collection of related tools.\\nagents.agent_toolkits.file_management.toolkit.FileManagementToolkit\\nToolkit for interacting with a Local Files.\\nagents.agent_toolkits.github.toolkit.GitHubToolkit\\nGitHub Toolkit.\\nagents.agent_toolkits.gitlab.toolkit.GitLabToolkit\\nGitLab Toolkit.\\nagents.agent_toolkits.gmail.toolkit.GmailToolkit\\nToolkit for interacting with Gmail.\\nagents.agent_toolkits.jira.toolkit.JiraToolkit\\nJira Toolkit.\\nagents.agent_toolkits.json.toolkit.JsonToolkit\\nToolkit for interacting with a JSON spec.\\nagents.agent_toolkits.multion.toolkit.MultionToolkit\\nToolkit for interacting with the Browser Agent\\nagents.agent_toolkits.nla.tool.NLATool\\nNatural Language API Tool.\\nagents.agent_toolkits.nla.toolkit.NLAToolkit\\nNatural Language API Toolkit.\\nagents.agent_toolkits.office365.toolkit.O365Toolkit\\nToolkit for interacting with Office 365.\\nagents.agent_toolkits.openapi.planner.RequestsDeleteToolWithParsing\\nA tool that sends a DELETE request and parses the response.\\nagents.agent_toolkits.openapi.planner.RequestsGetToolWithParsing\\nRequests GET tool with LLM-instructed extraction of truncated responses.\\nagents.agent_toolkits.openapi.planner.RequestsPatchToolWithParsing\\nRequests PATCH tool with LLM-instructed extraction of truncated responses.\\nagents.agent_toolkits.openapi.planner.RequestsPostToolWithParsing\\nRequests POST tool with LLM-instructed extraction of truncated responses.\\nagents.agent_toolkits.openapi.planner.RequestsPutToolWithParsing\\nRequests PUT tool with LLM-instructed extraction of truncated responses.\\nagents.agent_toolkits.openapi.spec.ReducedOpenAPISpec(...)\\nA reduced OpenAPI spec.\\nagents.agent_toolkits.openapi.toolkit.OpenAPIToolkit\\nToolkit for interacting with an OpenAPI API.\\nagents.agent_toolkits.openapi.toolkit.RequestsToolkit\\nToolkit for making REST requests.\\nagents.agent_toolkits.playwright.toolkit.PlayWrightBrowserToolkit\\nToolkit for PlayWright browser tools.', metadata={'source': 'danny-moldovan-qa-using-vector-databases-lp/apidocs/api.python.langchain.com/en/latest/api_reference.html'}),\n",
       "  Document(page_content='Chat prompt template for the agent scratchpad.\\nagents.self_ask_with_search.base.SelfAskWithSearchAgent\\nAgent for the self-ask-with-search paper.\\nagents.self_ask_with_search.base.SelfAskWithSearchChain\\n[Deprecated] Chain that does self-ask with search.\\nagents.structured_chat.base.StructuredChatAgent\\nStructured Chat Agent.\\nagents.structured_chat.output_parser.StructuredChatOutputParser\\nOutput parser for the structured chat agent.\\nagents.structured_chat.output_parser.StructuredChatOutputParserWithRetries\\nOutput parser with retries for the structured chat agent.\\nagents.tools.InvalidTool\\nTool that is run when invalid tool name is encountered by agent.\\nagents.xml.base.XMLAgent\\nAgent that uses XML tags.\\nFunctions¶\\nagents.agent_iterator.rebuild_callback_manager_on_set(...)\\nDecorator to force setters to rebuild callback mgr\\nagents.agent_toolkits.conversational_retrieval.openai_functions.create_conversational_retrieval_agent(...)\\nA convenience method for creating a conversational retrieval agent.\\nagents.agent_toolkits.conversational_retrieval.tool.create_retriever_tool(...)\\nCreate a tool to do retrieval of documents.\\nagents.agent_toolkits.csv.base.create_csv_agent(...)\\nCreate csv agent by loading to a dataframe and using pandas agent.\\nagents.agent_toolkits.json.base.create_json_agent(...)\\nConstruct a json agent from an LLM and tools.\\nagents.agent_toolkits.openapi.base.create_openapi_agent(...)\\nConstruct an OpenAPI agent from an LLM and tools.\\nagents.agent_toolkits.openapi.planner.create_openapi_agent(...)\\nInstantiate OpenAI API planner and controller for a given spec.\\nagents.agent_toolkits.openapi.spec.reduce_openapi_spec(spec)\\nSimplify/distill/minify a spec somehow.\\nagents.agent_toolkits.pandas.base.create_pandas_dataframe_agent(llm,\\xa0df)\\nConstruct a pandas agent from an LLM and dataframe.\\nagents.agent_toolkits.powerbi.base.create_pbi_agent(llm)\\nConstruct a Power BI agent from an LLM and tools.\\nagents.agent_toolkits.powerbi.chat_base.create_pbi_chat_agent(llm)\\nConstruct a Power BI agent from a Chat LLM and tools.\\nagents.agent_toolkits.python.base.create_python_agent(...)\\nConstruct a python agent from an LLM and tool.\\nagents.agent_toolkits.spark.base.create_spark_dataframe_agent(llm,\\xa0df)\\nConstruct a Spark agent from an LLM and dataframe.', metadata={'source': 'danny-moldovan-qa-using-vector-databases-lp/apidocs/api.python.langchain.com/en/latest/api_reference.html'})]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(), \n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever, \n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PromptTemplate(template=template, input_variables=[\"context\", \"question\"])}\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "# query = \"How to improve the performance of LangChain?\"\n",
    "query = \"What is HumanRejectedException?\"\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586f6e02-c6d8-42b1-b867-b6292c66bd65",
   "metadata": {},
   "source": [
    "Ask directly Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34de71d2-0b0c-4c8a-844e-47a07c0a86ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()  # Adjust temperature for creativity, e.g. temperature=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "976634f1-1cd6-4573-b6a3-79c2ac2a02a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nHumanRejectedException is a type of exception or error that occurs when a human user's input or action is rejected by a computer system or application. This can happen when the user's input does not match the expected format or criteria, or when the user does not have the necessary permissions or authorization to perform the requested action. HumanRejectedException is commonly used in software development to handle and communicate errors related to user interaction.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80771790-1df3-4046-9801-0e8560ac1797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
